[path]
wiki = D:/_IUST/entity_embedding/data/fawiki-first-50000-docs.txt
word2vec = D:/_IUST/entity_embedding/data/cc.fa.300.vec
canonical = D:/_IUST/entity_embedding/data/wiki-canonical-word-ids.txt
hyp_ctx = D:/_IUST/entity_embedding/data/hyp-ctx-word-ids.txt
model = D:/_IUST/entity_embedding/entity2vec/model.pickle

[limit]
word = 100000
entity = 1000

[param]
# data gen params
hyp_ctx_len = 10
unig_power = 0.6

# model params
vector_size = 300
words_per_ent = 20
neg_words = 5

# training params
lr = 0.3
margin = 0.1
epochs = 4
batch_size = 500
passes_wiki_words = 2
